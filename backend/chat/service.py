from openai import AsyncOpenAI
from config import settings
from typing import List, Dict

def get_system_prompt_for_chat_type(chat_type: int) -> str:
    """Генерирует системный промпт в зависимости от типа чата"""
    prompts = {
        0: """Ты - юридический помощник для малого бизнеса. Твоя задача - помогать предпринимателям разбираться в юридических вопросах, связанных с ведением бизнеса. Ты можешь давать советы по регистрации компаний, налогообложению, трудовому праву, договорам и другим юридическим аспектам. Всегда подчеркивай, что твои советы носят информационный характер и не заменяют консультацию профессионального юриста.""",
        
        1: """Ты - маркетинговый помощник для малого бизнеса. Твоя задача - помогать предпринимателям развивать свой бизнес через эффективный маркетинг. Ты можешь давать советы по продвижению в социальных сетях, контент-маркетингу, рекламе, брендингу, работе с клиентами и другим маркетинговым стратегиям. Предлагай практические и доступные решения для малого бизнеса.""",
        
        2: """Ты - финансовый помощник для малого бизнеса. Твоя задача - помогать предпринимателям управлять финансами своего бизнеса. Ты можешь давать советы по планированию бюджета, учету доходов и расходов, налогообложению, инвестициям, кредитованию и другим финансовым вопросам. Помогай принимать обоснованные финансовые решения.""",
        
        3: """Ты - HR помощник для малого бизнеса. Твоя задача - помогать предпринимателям в вопросах управления персоналом. Ты можешь давать советы по найму сотрудников, составлению должностных инструкций, мотивации персонала, решению конфликтов, соблюдению трудового законодательства и другим HR-вопросам. Предлагай решения, подходящие для небольших команд.""",
        
        4: """Ты - помощник по подсказкам и напоминаниям для малого бизнеса. Твоя задача - помогать предпринимателям не забывать о важных задачах, дедлайнах и действиях. Ты можешь напоминать о важных датах, помогать планировать задачи, давать подсказки по оптимизации рабочего процесса и повышению продуктивности. Будь дружелюбным и мотивирующим помощником.""",
        
        5: """Ты - гайд-помощник для малого бизнеса. Твоя задача - предоставлять пошаговые инструкции и руководства по различным аспектам ведения бизнеса. Ты можешь создавать подробные гайды по открытию бизнеса, регистрации, работе с клиентами, использованию различных инструментов и сервисов, решению типичных проблем и другим вопросам. Структурируй информацию четко и понятно."""
    }
    
    return prompts.get(chat_type, "Ты - помощник для малого бизнеса. Готов помочь с различными вопросами.")

class LLMService:
    def __init__(self):
        self.client = AsyncOpenAI(
            api_key=settings.OPEN_ROUTER_API_KEY,
            base_url=settings.OPEN_ROUTER_BASE_URL,
            default_headers={
                "HTTP-Referer": "https://github.com/your-repo",  # Optional
                "X-Title": "Goooooooooool",  # Optional
            }
        )
        self.model = settings.OPEN_ROUTER_MODEL
    
    async def generate_response(self, messages: List[Dict[str, str]]) -> str:
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                timeout=60.0
            )
            return response.choices[0].message.content
        except Exception as e:
            raise Exception(f"Error calling LLM: {str(e)}")
    
    def format_messages_for_llm(self, messages: List) -> List[Dict[str, str]]:
        formatted = []
        first_assistant_message = True
        
        for msg in messages:
            if msg.is_user == 1:
                role = "user"
            else:
                # Эт первое сообщение на системный 
                if first_assistant_message:
                    role = "system"

                    first_assistant_message = False
                else:
                    role = "assistant"
            
            formatted.append({
                "role": role,
                "content": msg.text
            })
        return formatted

llm_service = LLMService()

